{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Batch Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we compare the fairness of the different batch algorithms and experiment with ways to improve it.\n",
    "\n",
    "We define the fairness as the amount of samples taken from each class. For simplicity sake we will only use two classes and define the fairness as: \n",
    "$$\n",
    "Fairness = \\frac{amount\\_of\\_samples\\_from\\_class}{amount\\_of\\_total\\_samples}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "\n",
    "# sklearn\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "from skactiveml.pool import UncertaintySampling, BatchBALD\n",
    "from skactiveml.utils import MISSING_LABEL\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fairness(samples, label):\n",
    "    amount = 0\n",
    "    for sample in samples:\n",
    "        if sample == label:\n",
    "            amount += 1 \n",
    "    return amount / len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def al_batch_fairness(iterations=100, batch_size=1, weights = [0.8, 0.2], data_size=400, query_count=10):\n",
    "    data = []\n",
    "    qs = UncertaintySampling(method='entropy')\n",
    "    for rand in range(iterations):\n",
    "        # Create the data\n",
    "        Xf, yf = make_classification(n_samples=data_size, n_features=2, n_redundant=0, weights=weights, random_state=rand)\n",
    "        y = np.full(shape=yf.shape, fill_value=MISSING_LABEL)\n",
    "        \n",
    "        clf = SklearnClassifier(LogisticRegression(), classes=np.unique(yf))\n",
    "        clf.fit(Xf, y)\n",
    "        out = []\n",
    "        for _ in range(query_count):\n",
    "            query_idx = qs.query(Xf, y, clf=clf, batch_size=batch_size)\n",
    "            y[query_idx] = yf[query_idx]\n",
    "            clf.fit(Xf, y)\n",
    "            \n",
    "            out.append(check_fairness(yf[query_idx], 1))\n",
    "        data.append(out)\n",
    "    return np.mean(np.array(data), axis=0)\n",
    "\n",
    "def al_bald_fairness(iterations=100, batch_size=1, weights = [0.8, 0.2], data_size=400, query_count=10):\n",
    "    data = []\n",
    "    qs = BatchBALD()\n",
    "    for rand in range(iterations):\n",
    "        # Create the data\n",
    "        Xf, yf = make_classification(n_samples=data_size, n_features=2, n_redundant=0, weights=weights, random_state=rand)\n",
    "        y = np.full(shape=yf.shape, fill_value=MISSING_LABEL)\n",
    "        ensemble = []\n",
    "        ensemble.append(SklearnClassifier(LogisticRegression(), classes=np.unique(yf)))\n",
    "        for clf in ensemble:\n",
    "            clf.fit(Xf, y)\n",
    "        out = []\n",
    "        for _ in range(query_count):\n",
    "            query_idx = qs.query(Xf, y, ensemble=ensemble, batch_size=batch_size)\n",
    "            y[query_idx] = yf[query_idx]\n",
    "\n",
    "            for clf in ensemble:\n",
    "                clf.fit(Xf, y)\n",
    "                \n",
    "            out.append(check_fairness(yf[query_idx], 1))\n",
    "        data.append(out)\n",
    "    return np.mean(np.array(data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_fairnesses = al_batch_fairness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bald_fairnesses = al_bald_fairness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal batch fairness: 0.363\n",
      "Batch bald fairness: 0.11099999999999999\n"
     ]
    }
   ],
   "source": [
    "print(f'Normal batch fairness: {np.mean(batch_fairnesses)}')\n",
    "print(f'Batch bald fairness: {np.mean(bald_fairnesses)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores seem to align with the performance of the models, meaning that if a model is more fair it would perform better. We want the scores to near 50% which is the best with normal batches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
