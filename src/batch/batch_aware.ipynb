{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch aware query strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These strategies keep in mind that the model will query multiple samples simultaneously, and tries to pick samples that don't give the same info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The core set approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **core set** is a subset of a  dataset, such that when a model is trained on the subset it will produce a function that is close to a model resulting from training on the entire dataset. The idea is to only select samples from the core set. Concrete we should **choose a batch such that when added to the labeled set, the maximum distance between an unlabeled example and a labeled example is minimized.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "from skactiveml.pool import KLDivergenceMaximization\n",
    "from skactiveml.utils import MISSING_LABEL\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def al_batch(clf, batch_size=1, iterations=1, data_size=100):\n",
    "    base_clf = clf\n",
    "    data = []\n",
    "    qs = KLDivergenceMaximization()\n",
    "    for rand in range(iterations):\n",
    "        # Create the data\n",
    "        X, y = make_classification(n_samples=data_size*4, n_features=2, n_redundant=0, weights=[0.8,0.2], random_state=rand)\n",
    "        Xf, Xt, yf, yt = train_test_split(X, y, random_state=rand);\n",
    "        clf = SklearnClassifier(base_clf, classes=np.unique(yf))\n",
    "        y = np.full(shape=yf.shape, fill_value=MISSING_LABEL)\n",
    "\n",
    "        clf.fit(Xf, y)\n",
    "        out = []\n",
    "        for _ in range(int(data_size/5)):\n",
    "            query_idx = qs.query(Xf, y, reg=clf, batch_size=batch_size)\n",
    "            y[query_idx] = yf[query_idx]\n",
    "            clf.fit(Xf, y)\n",
    "            out.append(clf.score(Xt, yt))\n",
    "        data.append(out)\n",
    "    return np.mean(np.array(data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brent/.conda/envs/ml-project/lib/python3.11/site-packages/skactiveml/classifier/_wrapper.py:320: UserWarning: The 'base_estimator' could not be fitted because of 'There is no labeled data.'. Therefore, the class labels of the samples are counted and will be used to make predictions. The class label distribution is `_label_counts=[0, 0]`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`reg`  has type `<class 'skactiveml.classifier._wrapper.SklearnClassifier'>`, but must have type `<class 'skactiveml.base.ProbabilisticRegressor'>`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m al_batch(LogisticRegression(), batch_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, data_size\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m)\n",
      "\u001b[1;32m/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m out \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(data_size\u001b[39m/\u001b[39m\u001b[39m5\u001b[39m)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     query_idx \u001b[39m=\u001b[39m qs\u001b[39m.\u001b[39mquery(Xf, y, reg\u001b[39m=\u001b[39mclf, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     y[query_idx] \u001b[39m=\u001b[39m yf[query_idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brent/OneDrive/Documents/school/hoger/informatica_mast1_sem1/ml/project/src/batch/batch_aware.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     clf\u001b[39m.\u001b[39mfit(Xf, y)\n",
      "File \u001b[0;32m~/.conda/envs/ml-project/lib/python3.11/site-packages/skactiveml/pool/_information_gain_maximization.py:137\u001b[0m, in \u001b[0;36mKLDivergenceMaximization.query\u001b[0;34m(self, X, y, reg, fit_reg, sample_weight, candidates, batch_size, return_utilities)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determines for which candidate samples labels are to be queried.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m    refers to samples in candidates.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m X, y, candidates, batch_size, return_utilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    134\u001b[0m     X, y, candidates, batch_size, return_utilities, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    135\u001b[0m )\n\u001b[0;32m--> 137\u001b[0m check_type(reg, \u001b[39m\"\u001b[39m\u001b[39mreg\u001b[39m\u001b[39m\"\u001b[39m, ProbabilisticRegressor)\n\u001b[1;32m    138\u001b[0m check_type(fit_reg, \u001b[39m\"\u001b[39m\u001b[39mfit_reg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mbool\u001b[39m)\n\u001b[1;32m    140\u001b[0m X_eval \u001b[39m=\u001b[39m X[is_unlabeled(y, missing_label\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing_label_)]\n",
      "File \u001b[0;32m~/.conda/envs/ml-project/lib/python3.11/site-packages/skactiveml/utils/_validation.py:665\u001b[0m, in \u001b[0;36mcheck_type\u001b[0;34m(obj, name, target_vals, indicator_funcs, *target_types)\u001b[0m\n\u001b[1;32m    659\u001b[0m         error_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     error_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    661\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m be accepted by one of the following custom boolean \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    662\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunctions: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mset\u001b[39m(i_f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mi_f\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mindicator_funcs)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    663\u001b[0m     )\n\u001b[0;32m--> 665\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(error_str \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: `reg`  has type `<class 'skactiveml.classifier._wrapper.SklearnClassifier'>`, but must have type `<class 'skactiveml.base.ProbabilisticRegressor'>`."
     ]
    }
   ],
   "source": [
    "data = al_batch(LogisticRegression(), batch_size=5, data_size=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
